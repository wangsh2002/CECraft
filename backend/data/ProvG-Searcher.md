# ProvG-Searcher: 基于图表示学习的高效溯源图搜索方法

<!--

副标题：从海量系统日志中快速定位高级持续性威胁 (APT)

汇报人：

$$您的名字$$



日期：202X年X月X日

-->

## P1. 引言：当情报遇上现实——一个具体的威胁狩猎场景

- **场景描述**：
  - 假设我们收到一条威胁情报：黑客正在利用 Nginx 服务器漏洞，下载恶意载荷并提权执行。
  - **攻击链路**：`Network` -> `Nginx` -> `Passwd` (File) -> `pEjb` (Malware) -> `Root Access`。
- **面临的挑战**：
  - 企业的系统级溯源图（Provenance Graph）包含数百万个节点和边。
  - 这就好比在大海捞针：我们需要在庞大的图中找到那个特定的红色小图（Query Graph）。
- **核心问题**：
  - 如何根据已知的攻击模式（查询图），在海量的历史日志图（目标图）中，**毫秒级**地判定是否存在该攻击行为？
  - 这就是 **ProvG-Searcher** 要解决的问题。

<!--

演讲备注：

这一页直接引用论文 Figure 1 的例子。左上角是情报描述的攻击模式（Query），右下角是复杂的真实系统图（Target）。

强调这本质上是一个“子图匹配”问题，但在安全领域，由于图的规模巨大，这是极其困难的。

-->

## P2. 背景：APT 攻击与系统审计日志

- **APT (高级持续性威胁) 的特点**：
  - 长期潜伏、低频操作、跨进程/跨文件传播。
  - 传统的基于签名（Signature-based）的检测手段失效。
- **数据源：系统审计日志 (Audit Logs)**：
  - 记录了系统实体（进程、文件、网络套接字）之间的交互。
  - 例如：Linux Auditd, Windows ETW。
- **痛点**：
  - 日志量巨大（每天每台机器可达 GB 级）。
  - 语义割裂，单条日志难以看出攻击全貌。

## P3. 解决方案演进：从日志到溯源图 (Provenance Graph)

- **什么是溯源图？**
  - 将离散的日志事件串联起来。
  - 节点（Nodes）：系统实体（Process, File, Socket）。
  - 边（Edges）：系统调用/因果关系（Fork, Read, Write, Connect）。
- **溯源图的价值**：
  - **上下文关联**：能看到数据的来龙去脉（Data Lineage）。
  - **因果分析**：能追溯攻击的根源（Root Cause Analysis）。
- **当前的应用方向**：
  - 异常检测、取证分析、以及本论文关注的——**威胁狩猎 (Threat Hunting)**。

## P4. 核心任务：假设驱动的威胁狩猎

- **被动防御 vs. 主动狩猎**：
  - 不等待报警，而是假设系统已受陷。
  - 利用外部威胁情报（CTI）构建查询。
- **技术抽象**：
  - **输入**：威胁情报转化为“查询图” ($G_Q$)。
  - **对象**：历史日志构建的“系统溯源图” ($G$)。
  - **操作**：判断 $G_Q$ 是否是 $G$ 的子图（Subgraph Isomorphism）。
- **难点**：
  - **子图同构是 NP-Complete 问题**。
  - 在数千万节点的图中进行精确匹配是不现实的。

## P5. 现有方法的局限性

- **非学习类方法 (如 Poirot)**：
  - **机制**：基于启发式搜索，在查询时遍历大图。
  - **缺点**：计算都在“查询时”发生，速度慢，无法应对大规模并发查询。
- **早期学习类方法 (如 DeepHunter)**：
  - **机制**：利用 GNN 学习图嵌入，计算相似度。
  - **缺点**：
    - 依赖 IoC（入侵指标）作为种子节点，如果 IoC 缺失则失效。
    - 通常采用成对比较（Pairwise），计算复杂度依然较高。
    - 无法很好地处理溯源图特有的“依赖爆炸”问题。

## P6. ProvG-Searcher 的设计愿景与方向

- **核心理念**：将昂贵的计算转移到**离线阶段**。
- **三大突破方向**：
  1. **从“在线搜索”转向“离线索引”**：提前计算好系统图的特征嵌入。
  2. **从“精确匹配”转向“向量空间关系”**：利用序嵌入（Order Embedding）将图的包含关系映射为向量的大小关系。
  3. **从“原始全图”转向“语义子图”**：通过以进程为中心的切分和行为保留的归约，解决图过大的问题。

## P7. 系统整体架构 (Overview)

- **阶段一：离线处理 (Offline Phase)**
  - 图构建与简化 (Simplification)。
  - 图切分 (Partitioning) -> Ego-Graphs。
  - 表示学习 (Learning)：训练 GNN 模型。
  - 嵌入生成 (Embedding Creation)：生成向量数据库。
- **阶段二：在线查询 (Online Phase)**
  - 将查询图转换为向量。
  - **轻量级比较**：在向量空间中直接判定子图关系。
  - 输出匹配结果。

## P8. 挑战分析 (1/2)：规模与拓扑结构

- **Challenge #1: 图规模巨大 (Size of Graphs)**
  - 系统活动频繁，导致图节点和边数量极大。
  - **难题**：GNN 的深度和宽度受限，难以直接处理数百万节点的图。
- **Challenge #2: 高度数节点与依赖爆炸 (High-Degree Nodes)**
  - 某些节点（如 DNS 服务器、缓存文件）连接数以万计。
  - **难题**：
    - **依赖爆炸**：如果不加控制，遍历会迅速覆盖全图。
    - **过平滑 (Over-smoothing)**：GNN 聚合过多邻居信息，导致特征模糊，无法区分异常。

## P9. 挑战分析 (2/2)：语义、时序与学习目标

- **Challenge #3: 时间顺序的保留 (Preserving Time Order)**
  - 溯源图是有向且有时序的。忽略时间会导致虚假的因果关系。
  - **难题**：标准 GNN 聚合通常是并行的，难以捕捉严格的因果时序。
- **Challenge #4: 查询与日志的语义鸿沟 (Semantic Gap)**
  - 威胁情报是高度概括的（如“浏览器进程”），而日志是具体的（如 `firefox.exe` PID:1234）。
  - **难题**：如何让模糊的查询匹配到具体的日志？
- **Challenge #5: 学习目标的设定 (Setting a Learning Objective)**
  - **难题**：如何设计训练任务，让模型能学会判定“子图包含关系”？特别是如何生成高质量的负样本（即“很像子图但不是子图”的样本）？

## P10. 应对策略一：图简化与语义抽象 (Addressing C1 & C4)

- **基础简化 (C1)**：
  - 合并线程到父进程；合并短时间内的重复网络连接。
- **实体抽象 (Abstraction) (C4)**：
  - **解决语义鸿沟**：将具体的路径（如 `/home/user/doc.pdf`）抽象为类别（如 `Home File`）。
  - **效果**：
    - 统一了查询图和目标图的“语言”。
    - 增强了模型的泛化能力，使其学习“行为模式”而非“具体路径”。
    - Linux 下使用了约 70 种抽象类别。

## P11. 应对策略二：缓解依赖爆炸与版本化 (Addressing C2 & C3)

- **引入时间维度 (Graph Versioning) (C3)**：
  - 节点不是静态的。每当节点状态发生关键变化，生成一个新的“版本节点”。
  - **效果**：切断了不合逻辑的时间依赖，确保因果流严格遵循时间顺序。
- **设置汇点 (Sink Nodes) (C2)**：
  - **解决过平滑**：对于高频访问但无信息增益的节点（如只读配置、日志文件），将其设为 Sink。
  - **效果**：阻止 GNN 聚合时的无效信息传播，专注于有意义的交互。

## P12. 应对策略三：Ego-graph 切分 (Addressing C1)

- **以进程为中心**：
  - 全图学习太难，且攻击行为通常是局部的。
- **切分策略**：
  - 提取每个进程节点及其 $k$-跳邻居（$k$-hop neighbors）。
  - 形成一组 **Ego-graphs**（自我中心图）。
  - $k$ 通常取 3，对应 GNN 的层数。
- **意义**：
  - 将大图匹配问题，分解为多个小图的匹配问题，规避了全图处理的内存瓶颈。

## P13. 应对策略四：行为保留的图归约 (Addressing C1 & C4)

- **问题背景**：
  - 一个进程可能写了 100 个临时文件，生成 100 个相似的邻居分支。这既冗余又会导致数据偏差。
- **解决方案算法**：
  1. **哈希计算**：基于邻居结构迭代计算节点哈希。
  2. **去重**：对于哈希值相同的分支（即行为结构相同），只保留一个代表性分支。
- **结果**：
  - 图的规模大幅减小（从数万边减至几十边），但**攻击模式的结构特征被完整保留**。

## P14. 核心算法：图表示学习 (Learning Subgraph Relationships)

- **目标**：

  - 学习一个映射函数 $\eta$，将图 $G$ 映射为向量 $z$。

- **关键创新：序嵌入 (Order Embeddings)**

  - 传统的图相似度学习（如欧氏距离）不适合描述“包含”关系。

  - **序嵌入的核心思想**：利用向量空间的偏序关系来模拟图的子图关系。

  - 数学定义：

    $G_q \subseteq G_p \iff \forall i, z_{p_i} \ge z_{q_i}$

  - **解释**：如果图 Q 是图 P 的子图，那么 P 的向量在每一个维度上都应该“大于等于”Q 的向量（在非负空间中）。

## P15. 损失函数 (Loss Function)

- **违规惩罚函数 (Order Violation Penalty)**：
  - 如果 $G_q$ 是 $G_p$ 的子图，但向量不满足 $z_p \ge z_q$，则需要惩罚。
  - 公式：$E(z_q, z_p) = ||\max(0, z_q - z_p)||^2$![img]()
  - 意义：只有当 $z_q$ 某些维度超过 $z_p$ 时才有惩罚值，否则为 0。
- **Max-margin Loss**：
  - 优化目标是让正样本对的惩罚趋向于 0，负样本对的惩罚超过阈值。

## P16. 训练样本生成 (Addressing C5)

- **解决学习目标挑战 (C5)**：
  - 为了让模型学会识别“包含关系”，样本质量至关重要。
- **正样本生成 (**$G_q^+, G_p$**)**：
  - 从 $G_p$ 中采样一条路径并扩展，利用**路径频率**采样避免过拟合常见行为。
- **负样本生成 (**$G_q^-, G_p$**)**：
  - **策略**：选择同类进程的其他 Ego-graph，或者修改流路径。
  - **严格校验**：确保生成的负样本确实不满足子图关系，避免给模型喂“假阴性”数据。

## P17. 在线匹配流程 (Online Phase)

1. **查询处理**：
   - 接收威胁情报图 $G_Q$。
   - 进行同样的图简化和切分，生成查询 Ego-graphs $\{G_{q_1}, G_{q_2}, ...\}$。
   - 通过模型生成嵌入向量 $z_q$。
2. **快速筛选**：
   - 计算 $E(z_q, z_p)$。如果惩罚值为 0（或低于极小阈值），则判定为潜在匹配。
3. **匹配评分**：
   - 将所有匹配的局部图拼凑起来，计算其覆盖了多少查询图的内容。
   - 使用软决策指标（Soft-decision metric），容忍少量的结构差异。

## P18. 实验设置

- **数据集**：DARPA Transparent Computing (TC) Dataset。
  - 包含 Theia, Trace, Cadets, FiveDirections 等数据集。
  - 涵盖 Linux, FreeBSD, Windows 多种操作系统。
- **攻击场景**：
  - Nginx 后门、Firefox 后门、浏览器插件窃密、钓鱼邮件等 8 种真实 APT 场景。
- **基准对比 (Baselines)**：
  - **Poirot** (经典启发式搜索)。
  - **DeepHunter** (基于 GNN + IoC 过滤)。
  - **SimGNN**, **IsoRankN** (通用图匹配算法)。

## P19. 实验结果：图简化的有效性

- **数据缩减惊人**：
  - 以 Theia 数据集为例：
    - 初始 Ego-graph：平均 20.6万节点，1300万边。
    - 简化+去依赖+归约后：平均 **19 个节点，38 条边**。
- **价值**：
  - 极大地降低了 GNN 的训练难度和推理时间。
  - 同时保留了足以区分攻击行为的结构特征。

## P20. 实验结果：子图关系判断准确率

- **ROC 曲线表现**：
  - 在所有数据集上，AUC 均超过 **96%**。
  - 在 Cadets 数据集上达到 98.3%。
- **Order Embedding 的有效性**：
  - 证明了这种简单的向量比较方法（$z_p \ge z_q$）能够极其准确地捕捉复杂的拓扑包含关系。

## P21. 实验结果：检测真实攻击 (Case Studies)

- **场景测试**：
  - 针对 DARPA 的 8 个攻击场景，ProvG-Searcher 全部成功检测。
  - **误报率极低**：在数以万计的背景图中，只返回了极少数的候选图，且都与攻击高度相关。
- **定位能力**：
  - 匹配到的子图不仅包含攻击节点，还过滤掉了无关的系统噪声。
  - 匹配得分均在 0.9 以上。

## P22. 与 SOTA 方法的对比

| **指标**           | **ProvG-Searcher**       | **Poirot** | **DeepHunter** |
| ------------------ | ------------------------ | ---------- | -------------- |
| **准确率 (Theia)** | **99.83%**               | 97.44%     | 83.67%         |
| **误报率 (FPR)**   | **0.02%**                | 5.07%      | 21.19%         |
| **在线查询耗时**   | **秒级** (48s / 10k查询) | 小时级     | 分钟级         |

- **分析**：
  - Poirot 虽准确但速度太慢，且随图规模指数级变慢。
  - DeepHunter 依赖 IoC，且误报率较高。
  - ProvG-Searcher 实现了速度与准确率的双赢。

## P23. 鲁棒性分析 (Robustness)

- **应对模糊查询**：
  - 现实中，情报图可能不完整，或者攻击者稍微改变了步骤。
- **实验设计**：
  - 随机删除查询图 15%-45% 的节点或边。
- **结果**：
  - 即使删除了 15% 的节点，AUC 依然保持在 93% 以上。
  - 证明了模型学习到了**结构语义**，而非死板的精确匹配。

## P24. 消融实验 (Ablation Study)

- **哪些组件最重要？**
  - **行为保留归约 (BR)**：去掉 BR 步骤，准确率下降约 3-5%。说明去除冗余对模型学习至关重要。
  - **子图匹配框架 (SM)**：将大图切分为 3-hop 小图比直接处理 5-hop 大图效果更好（提升约 5%）。
- **结论**：
  - 合理的图预处理（简化、切分）是图学习成功的关键，其重要性不亚于模型本身。

## P25. 总结与贡献

1. **高效性**：提出了一种基于“离线学习 + 在线比较”的威胁狩猎新范式，解决了大规模溯源图搜索的效率瓶颈。
2. **创新表示**：首次在溯源图领域应用 **Order Embeddings**，巧妙解决了子图同构判定的难题。
3. **图工程**：设计了一套完整的、保留行为语义的图简化与切分流程，使 GNN 处理海量日志成为可能。
4. **性能卓越**：在准确率、误报率和查询速度上全面优于现有最先进方法（SOTA）。

## P26. 未来展望

- **更深层的 GNN**：
  - 目前使用 3-4 层网络，探索更深层网络以捕获更长距离的攻击链。
- **跨系统通用性**：
  - 设计与操作系统无关的实体表示，使模型能在 Linux/Windows 间迁移。
- **处理重复行为**：
  - 针对勒索软件（大量重复的文件加密操作）等特定场景进行优化建模。