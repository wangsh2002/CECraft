from __future__ import annotations

import os
import json
from typing import List, Optional, Dict, Any

from dotenv import load_dotenv
from openai import OpenAI
from pymilvus import connections, Collection, utility

# å°è¯•å¯¼å…¥ dashscope ç”¨äº Rerank
try:
    import dashscope
except ImportError:
    dashscope = None


load_dotenv()


def _call_embedding_api(texts: List[str], api_url: str, api_key: Optional[str]) -> List[List[float]]:
    """
    è°ƒç”¨åµŒå…¥æ¨¡å‹APIï¼Œè·å–æ–‡æœ¬çš„åµŒå…¥è¡¨ç¤ºã€‚
    Args:
        texts (List[str]): éœ€è¦è·å–åµŒå…¥è¡¨ç¤ºçš„æ–‡æœ¬åˆ—è¡¨ã€‚
        api_url (str): åµŒå…¥æ¨¡å‹APIçš„URLã€‚
        api_key (Optional[str]): ç”¨äºAPIè®¤è¯çš„å¯†é’¥ã€‚
    Returns:
        List[List[float]]: æ–‡æœ¬çš„åµŒå…¥è¡¨ç¤ºåˆ—è¡¨ã€‚
    """
    texts = [t.replace("\n", " ") for t in texts]
    
    client = OpenAI(api_key=api_key, 
                    base_url=api_url)
    
    resp = client.embeddings.create(model="text-embedding-v3", 
                                    input=texts, 
                                    encoding_format="float")
    
    data_items = sorted(resp.data, key=lambda x: x.index)

    embeddings = [item.embedding for item in data_items]

    return embeddings


def _ensure_milvus_connection(host: str, port: str):
    """
    è¿æ¥Milvus
    Args:
        host (str): Milvusä¸»æœºåœ°å€ã€‚
        port (str): Milvusç«¯å£å·ã€‚
    """
    try:
        connections.connect(host=host, port=port)
    except Exception as e:
        raise RuntimeError(f"æ— æ³•è¿æ¥åˆ°Milvus: {e}")


def _generate_answer_with_llm(query: str, context: str, api_url: str, api_key: Optional[str]) -> str:
    """Use the OpenAI-compatible API to generate a final answer given query and retrieved context.

    Returns the text response from the model.
    """
    client = OpenAI(api_key=api_key, base_url=api_url)

    prompt = (
        "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©ç†ã€‚ä½¿ç”¨ä¸‹é¢çš„æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼š\n\n"
        "ä¸Šä¸‹æ–‡:\n" + context + "\n\n"
        "é—®é¢˜: " + query + "\n\n"
        "è¯·ç»™å‡ºç®€æ˜ã€ä¸­æ–‡çš„æ‘˜è¦å¼å›ç­”ï¼Œä»…åŸºäºä¸Šé¢çš„æ£€ç´¢ä¸Šä¸‹æ–‡å›ç­”ï¼Œä¸è¦åˆ—å‡ºæˆ–æš´éœ²åŸå§‹ç‰‡æ®µçš„è·¯å¾„ã€chunk ç´¢å¼•æˆ–å…¶ä»–å…ƒæ•°æ®ã€‚ä¸¥ç¦å‡­ç©ºç¼–é€ äº‹å®ï¼›å¦‚æœä¸Šä¸‹æ–‡ä¸è¶³ä»¥å›ç­”ï¼Œè¯·æ˜ç¡®è¯´æ˜å¹¶ç»™å‡ºå»ºè®®ã€‚"
    )

    resp = None
    resp = client.chat.completions.create(model="qwen-turbo", 
                                          messages=[{"role": "user", "content": prompt}])
    # ä»å“åº”ä¸­æå–æ–‡æœ¬ï¼Œå…¼å®¹å¤šç§è¿”å›æ ¼å¼
    text = None
    try:
        text = getattr(resp, "output_text", None)
    except Exception:
        text = None

    if not text:
        try:
            out = getattr(resp, "output", None)
            if out and isinstance(out, list) and len(out) > 0:
                parts = []
                for item in out:
                    cont = item.get("content") if isinstance(item, dict) else None
                    if cont and isinstance(cont, list):
                        for c in cont:
                            if isinstance(c, dict) and c.get("type") == "output_text":
                                parts.append(c.get("text", ""))
                            elif isinstance(c, str):
                                parts.append(c)
                text = "".join(parts)
        except Exception:
            text = None

    if not text:
        try:
            choices = getattr(resp, "choices", None)
            if choices and len(choices) > 0:
                # handle both object and dict shapes
                first = choices[0]
                if hasattr(first, "message"):
                    text = first.message.get("content") if isinstance(first.message, dict) else getattr(first.message, "content", None)
                else:
                    # dict-like
                    text = first.get("text") if isinstance(first, dict) else None
        except Exception:
            text = None

    if not text:
        raise RuntimeError("æ— æ³•ä»å¤§æ¨¡å‹å“åº”ä¸­æå–æ–‡æœ¬è¾“å‡º")

    return text


def retrieve_resume_examples(query: str, topk: Optional[int] = 5) -> str:
    """
    æŸ¥è¯¢RAGå‘é‡æ•°æ®åº“ï¼Œè·å–ç›¸å…³æ–‡æœ¬ç‰‡æ®µå¹¶ç”Ÿæˆå›ç­”
    Args:
        query (str): æŸ¥è¯¢æ–‡æœ¬ã€‚
        topk (Optional[int]): è¿”å›çš„ç›¸ä¼¼æ–‡æœ¬ç‰‡æ®µæ•°é‡ï¼Œé»˜è®¤ä¸º5
    Returns:
        str: å¤§æ¨¡å‹ç”Ÿæˆçš„å›ç­”
    """
    api_url = os.getenv("DASHSCOPE_API_URL")
    api_key = os.getenv("DASHSCOPE_API_KEY")
    milvus_host = os.getenv("MILVUS_HOST", "127.0.0.1")
    milvus_port = os.getenv("MILVUS_PORT", "19530")
    collection_name = os.getenv("RAG_COLLECTION", "md_collection")

    if not api_url:
        raise RuntimeError("API URL is not set")

    # è¿æ¥Mlivus
    _ensure_milvus_connection(milvus_host, milvus_port)

    # åŠ è½½é›†åˆ
    if not utility.has_collection(collection_name):
        raise RuntimeError(f"Milvus collection '{collection_name}' does not exist")

    coll = Collection(collection_name)
    coll.load()

def _generate_sub_queries(query: str, api_url: str, api_key: Optional[str]) -> List[str]:
    """
    ä½¿ç”¨ LLM ç”Ÿæˆç›¸å…³çš„å­æŸ¥è¯¢ï¼Œç”¨äºå¤šè·¯å¬å›
    """
    client = OpenAI(api_key=api_key, base_url=api_url)
    prompt = (
        f"ä½ æ˜¯ä¸€ä¸ªæœç´¢ä¸“å®¶ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ '{query}'ï¼Œç”Ÿæˆ 3 ä¸ªç›¸å…³çš„æœç´¢æŸ¥è¯¢ï¼Œ"
        "ä»¥ä¾¿ä»ç®€å†æ•°æ®åº“æˆ–å²—ä½æè¿°ä¸­æ£€ç´¢åˆ°æ›´å…¨é¢çš„ä¿¡æ¯ã€‚\n"
        "è¯·ç›´æ¥è¾“å‡º 3 ä¸ªæŸ¥è¯¢ï¼Œæ¯è¡Œä¸€ä¸ªï¼Œä¸è¦åŒ…å«ç¼–å·æˆ–é¢å¤–è§£é‡Šã€‚"
    )
    
    try:
        resp = client.chat.completions.create(
            model="qwen-turbo",
            messages=[{"role": "user", "content": prompt}]
        )
        content = resp.choices[0].message.content
        if not content:
            return [query]
            
        sub_queries = [line.strip() for line in content.split('\n') if line.strip()]
        return [query] + sub_queries[:3] # åŒ…å«åŸå§‹æŸ¥è¯¢
    except Exception:
        return [query]


def _rerank_documents(query: str, docs: List[Dict[str, Any]], top_n: int) -> List[Dict[str, Any]]:
    """
    ä½¿ç”¨ DashScope Rerank æ¨¡å‹å¯¹æ–‡æ¡£è¿›è¡Œé‡æ’åº
    """
    if not docs:
        return []
        
    # å¦‚æœæ²¡æœ‰ dashscope åº“æˆ–æ²¡æœ‰ API Keyï¼Œç›´æ¥è¿”å›å‰ N ä¸ª
    api_key = os.getenv("DASHSCOPE_API_KEY")
    if not dashscope or not api_key:
        print("âš ï¸ [RAG] DashScope SDK not found or API Key missing. Skipping Rerank.")
        return docs[:top_n]

    try:
        dashscope.api_key = api_key
        # æå–æ–‡æœ¬åˆ—è¡¨
        doc_texts = [d.get("text", "") or d.get("text_snippet", "") for d in docs]
        
        # è°ƒç”¨ Rerank API
        # æ³¨æ„ï¼šDashScope Rerank API è°ƒç”¨æ–¹å¼å¯èƒ½éšç‰ˆæœ¬å˜åŒ–ï¼Œè¿™é‡Œä½¿ç”¨æ ‡å‡†è°ƒç”¨
        resp = dashscope.TextReRank.call(
            model='gte-rerank',
            query=query,
            documents=doc_texts,
            top_n=top_n,
            return_documents=True
        )
        
        if resp.status_code == 200:
            # æ ¹æ®è¿”å›çš„ index é‡æ–°ç»„ç»‡ docs
            reranked_docs = []
            for item in resp.output.results:
                original_idx = item.index
                doc = docs[original_idx]
                doc['rerank_score'] = item.relevance_score
                reranked_docs.append(doc)
            print(f"âœ… [RAG] Rerank successful. Top score: {reranked_docs[0]['rerank_score']}")
            return reranked_docs
        else:
            print(f"âš ï¸ [RAG] Rerank API failed: {resp.message}. Fallback to original order.")
            return docs[:top_n]
            
    except Exception as e:
        print(f"âš ï¸ [RAG] Rerank exception: {e}. Fallback to original order.")
        return docs[:top_n]


def search_and_rerank(query: str, top_k: int = 5) -> List[Dict[str, Any]]:
    """
    æ‰§è¡Œå®Œæ•´çš„æ£€ç´¢æµç¨‹ï¼šQuery Expansion -> Vector Search -> Rerank
    è¿”å›æ–‡æ¡£åˆ—è¡¨ï¼Œä¾› Evaluation ä½¿ç”¨
    """
    api_url = os.getenv("DASHSCOPE_API_URL")
    api_key = os.getenv("DASHSCOPE_API_KEY")
    milvus_host = os.getenv("MILVUS_HOST", "127.0.0.1")
    milvus_port = os.getenv("MILVUS_PORT", "19530")
    collection_name = os.getenv("RAG_COLLECTION", "md_collection")

    if not api_url:
        raise RuntimeError("API URL is not set")

    _ensure_milvus_connection(milvus_host, milvus_port)

    if not utility.has_collection(collection_name):
        raise RuntimeError(f"Milvus collection '{collection_name}' does not exist")

    coll = Collection(collection_name)
    coll.load()

    # 1. æŸ¥è¯¢æ‰©å±•
    queries = _generate_sub_queries(query, api_url, api_key)
    print(f"ğŸ” [RAG] Expanded queries: {queries}")

    # 2. æ‰¹é‡å‘é‡åŒ–
    embeddings = _call_embedding_api(queries, api_url=api_url, api_key=api_key)
    if not embeddings:
        raise RuntimeError("Failed to obtain embedding for query")
    
    # 3. å‘é‡æ£€ç´¢ (æ‰©å¤§å¬å›èŒƒå›´ï¼Œä¸º Rerank å‡†å¤‡)
    # å¦‚æœæœ€ç»ˆéœ€è¦ top_k=5ï¼Œæˆ‘ä»¬å¬å› top_k * 3 æˆ–æ›´å¤š
    recall_k = top_k * 4 
    search_params = {"metric_type": "COSINE", "params": {"nprobe": 10}}
    limit_per_query = max(2, recall_k // len(queries) + 1)
    
    results = coll.search(embeddings, "embedding", param=search_params, limit=limit_per_query, output_fields=["metadata"])

    # 4. ç»“æœå»é‡ä¸åˆå¹¶
    unique_hits = {} 
    
    for hits in results:
        for hit in hits:
            meta_raw = hit.entity.get("metadata")
            if not meta_raw:
                continue
            try:
                meta = json.loads(meta_raw)
                key = (meta.get("source"), meta.get("chunk_index"))
                # ç¡®ä¿ meta ä¸­æœ‰ text å­—æ®µï¼Œå¦‚æœæ²¡æœ‰åˆ™å›é€€åˆ° snippet
                if 'text' not in meta:
                    meta['text'] = meta.get('text_snippet', '')
                
                if key not in unique_hits:
                    unique_hits[key] = {
                        "score": hit.score,
                        "meta": meta
                    }
                else:
                    if hit.score > unique_hits[key]["score"]:
                        unique_hits[key]["score"] = hit.score
            except:
                continue

    # åˆæ­¥æ’åº
    sorted_candidates = [item['meta'] for item in sorted(unique_hits.values(), key=lambda x: x["score"], reverse=True)]
    
    # 5. é‡æ’åº (Rerank)
    # åªå¯¹å‰ 50 ä¸ªå€™é€‰è¿›è¡Œé‡æ’åºï¼ŒèŠ‚çœæˆæœ¬
    candidates_for_rerank = sorted_candidates[:50]
    final_docs = _rerank_documents(query, candidates_for_rerank, top_n=top_k)
    
    return final_docs


def retrieve_resume_examples(query: str, topk: Optional[int] = 5) -> str:
    """
    æŸ¥è¯¢RAGå‘é‡æ•°æ®åº“ï¼Œè·å–ç›¸å…³æ–‡æœ¬ç‰‡æ®µå¹¶ç”Ÿæˆå›ç­”
    """
    api_url = os.getenv("DASHSCOPE_API_URL")
    api_key = os.getenv("DASHSCOPE_API_KEY")
    
    # è°ƒç”¨æ‹†åˆ†åçš„æ£€ç´¢å‡½æ•°
    final_docs = search_and_rerank(query, top_k=topk)

    if not final_docs:
        return "æœªæ‰¾åˆ°åŒ¹é…çš„ç»“æœã€‚"

    out_items: List[str] = []
    for doc in final_docs:
        # ä¼˜å…ˆä½¿ç”¨å®Œæ•´æ–‡æœ¬
        text_content = doc.get("text") or doc.get("text_snippet") or "(no content)"
        source = doc.get("source") or "(unknown)"
        chunk_index = doc.get("chunk_index")
        score = doc.get("rerank_score", 0)

        out = (
            f"source: {source} | chunk: {chunk_index} | score: {score}\n"
            f"{text_content}"
        )
        out_items.append(out)

    context = "\n\n---\n\n".join(out_items)

    answer = _generate_answer_with_llm(query=query, context=context, api_url=api_url, api_key=api_key)
    
    return answer


if __name__ == "__main__":
    q = "ä»€ä¹ˆæ˜¯æº¯æºå›¾ï¼Ÿ"
    try:
        print(retrieve_resume_examples(q))
    except Exception as e:
        print(f"æ£€ç´¢å¤±è´¥: {e}")
