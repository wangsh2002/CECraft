import asyncio
import os
import sys
from collections import defaultdict
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple


# 1) é…ç½® Python è·¯å¾„ï¼šç¡®ä¿èƒ½ import app.*
current_dir = os.path.dirname(os.path.abspath(__file__))
backend_dir = os.path.dirname(current_dir)
sys.path.insert(0, backend_dir)


try:
    from app.services.agent_workflow import llm_service
    from langchain_core.messages import HumanMessage
except Exception as e:
    print("é”™è¯¯ï¼šæ— æ³•å¯¼å…¥ app æ¨¡å—æˆ–åˆå§‹åŒ–é…ç½®å¤±è´¥ã€‚è¯·ç¡®ä¿åœ¨ backend ç›®å½•ä¸‹è¿è¡Œï¼Œä¸” backend/.env é…ç½®æ­£ç¡®ã€‚")
    print(f"è¯¦ç»†é”™è¯¯: {e}")
    raise


INTENTS: Tuple[str, ...] = (
    "chat",
    "modify",
    "research_consult",
    "research_modify",
)

RESEARCH_MODIFY_TOOLS: Tuple[str, ...] = (
    "web",
    "rag",
    "both",
)


@dataclass(frozen=True)
class Case:
    expected: str
    prompt: str
    expected_tool: Optional[str] = None


def build_cases() -> List[Case]:
    """æ¯ä¸ªæ„å›¾ 10 æ¡æ ·ä¾‹ï¼›research_modify ç»†åˆ† web/rag/both å„ 10 æ¡ã€‚

    æ³¨æ„ï¼š
    - å¤§ç±»ç”¨ Supervisor è¾“å‡ºçš„ next_agentã€‚
    - å½“ next_agent == research_modify æ—¶ï¼Œå†ç”¨ ToolRouter é€‰æ‹© web/rag/bothã€‚
    """

    # chatï¼šé—²èŠ/åŠŸèƒ½è¯¢é—®/é€šç”¨å»ºè®®ï¼ˆä¸è¦æ±‚æœç´¢ã€ä¸è¦æ±‚æ”¹ç®€å†ï¼‰
    chat_prompts = [
        "ä½ å¥½ï¼Œä½ æ˜¯è°ï¼Ÿèƒ½åšä»€ä¹ˆï¼Ÿ",
        "ä½ èƒ½ç®€å•ä»‹ç»ä¸€ä¸‹æ€ä¹ˆå†™ä¸€ä»½å¥½ç®€å†å—ï¼Ÿ",
        "æˆ‘æœ€è¿‘æœ‰ç‚¹ç„¦è™‘ï¼Œæ‰¾å·¥ä½œè¯¥æ€ä¹ˆè§„åˆ’ï¼Ÿ",
        "é¢è¯•æ—¶å¦‚ä½•è‡ªæˆ‘ä»‹ç»æ›´è‡ªç„¶ï¼Ÿç»™æˆ‘ä¸€ä¸ªé€šç”¨æ¨¡æ¿ã€‚",
        "æˆ‘æƒ³ä»åç«¯è½¬å‰ç«¯ï¼Œä½ è§‰å¾—å¯è¡Œå—ï¼Ÿ",
        "ä½ è§‰å¾—ç®€å†æœ€é‡è¦çš„ä¸‰ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ",
        "è¯·ç»™æˆ‘ä¸€äº›èŒä¸šå‘å±•å»ºè®®ï¼š3å¹´åç«¯å¦‚ä½•è¿›é˜¶ï¼Ÿ",
        "ä½ èƒ½è§£é‡Šä¸€ä¸‹ STAR æ³•åˆ™æ˜¯ä»€ä¹ˆå—ï¼Ÿ",
        "ä½ æ”¯æŒå“ªäº›æ ¼å¼çš„ç®€å†å†…å®¹ï¼Ÿ",
        "æˆ‘åº”è¯¥å¦‚ä½•é€‰æ‹©åŸå¸‚ï¼šåŒ—äº¬è¿˜æ˜¯ä¸Šæµ·ï¼Ÿ",
    ]

    # modifyï¼šæ˜ç¡®çš„æ–‡æœ¬æ¶¦è‰²/æ”¹å†™/ç¿»è¯‘/çº é”™ï¼ˆä¸å¼ºè°ƒå¯¹æ ‡å¸‚åœº/JD/è°ƒç ”ï¼‰
    modify_prompts = [
        "æŠŠè¿™å¥è¯æ¶¦è‰²å¾—æ›´ä¸“ä¸šï¼šæˆ‘è´Ÿè´£å†™ä»£ç ï¼Œä¿®bugï¼Œç»´æŠ¤æœåŠ¡å™¨ã€‚",
        "æŠŠè¿™æ®µç»å†æ”¹çŸ­ä¸€äº›ï¼ˆä¸¤å¥è¯ä»¥å†…ï¼‰ï¼šä¸»å¯¼æ¥å£å¼€å‘ï¼Œä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢ï¼Œæå‡å“åº”é€Ÿåº¦ã€‚",
        "è¯·çº æ­£é”™åˆ«å­—å¹¶ä¼˜åŒ–è¡¨è¾¾ï¼šæˆ‘ç†Ÿæ‚‰pyhtonå’Œflaskï¼Œèƒ½ç‹¬ç«‹å®Œæˆæ¥å£å¼€å‘ã€‚",
        "æŠŠä¸‹é¢å†…å®¹ç¿»è¯‘æˆè‹±æ–‡ï¼šç†Ÿæ‚‰ Pythonã€FastAPIï¼Œè´Ÿè´£è¿‡æ”¯ä»˜ç³»ç»Ÿçš„å¼€å‘ä¸ç»´æŠ¤ã€‚",
        "å¸®æˆ‘æŠŠè¯­æ°”æ”¹å¾—æ›´è‡ªä¿¡ï¼šæˆ‘å¯èƒ½åšè¿‡ä¸€äº›æ€§èƒ½ä¼˜åŒ–ã€‚",
        "æŠŠè¿™æ®µè¯æ”¹æˆè¦ç‚¹åˆ—è¡¨ï¼šæ­å»ºCI/CDï¼›ç›‘æ§æŠ¥è­¦ï¼›å®¹å™¨åŒ–éƒ¨ç½²ã€‚",
        "å¸®æˆ‘æŠŠè¿™æ®µæè¿°æ”¹æˆæ›´æœ‰å†²å‡»åŠ›ä½†ä¸å¤¸å¼ ï¼šä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½ï¼Œå‡å°‘çº¿ä¸Šè¶…æ—¶ã€‚",
        "æŠŠä¸‹é¢è¿™å¥è¯æ”¹æˆæ›´æ­£å¼ï¼šæˆ‘ä¼šç”¨Redisã€‚",
        "è¯·æŠŠè¿™æ®µè¯æŒ‰æŠ€æœ¯æ ˆæ‹†åˆ†å¹¶æ¶¦è‰²ï¼šåšè¿‡å¾®æœåŠ¡ï¼Œæ¶ˆæ¯é˜Ÿåˆ—ï¼Œç¼“å­˜å’Œæ—¥å¿—ç³»ç»Ÿã€‚",
        "å°†ä»¥ä¸‹å†…å®¹æ”¹å†™æˆç®€å†é£æ ¼ï¼šæˆ‘åœ¨å­¦æ ¡åšè¿‡å¾ˆå¤šé¡¹ç›®ï¼Œå­¦åˆ°äº†å¾ˆå¤šä¸œè¥¿ã€‚",
    ]

    # research_consultï¼šåªæƒ³æŸ¥ä¿¡æ¯ï¼ˆè–ªèµ„/é¢è¯•é¢˜/å…¬å¸/è¡Œä¸šè¶‹åŠ¿ï¼‰ï¼Œä¸è¦æ±‚æ”¹ç®€å†
    research_consult_prompts = [
        "å¸®æˆ‘æŸ¥ä¸€ä¸‹ 2025 å¹´ä¸Šæµ· Python åç«¯å·¥ç¨‹å¸ˆçš„è–ªèµ„èŒƒå›´ã€‚",
        "è¯·è°ƒç ”ä¸€ä¸‹ç°åœ¨å¤§å‚å¯¹ DevOps å·¥ç¨‹å¸ˆçš„æ ¸å¿ƒè¦æ±‚æœ‰å“ªäº›ï¼Ÿ",
        "å­—èŠ‚è·³åŠ¨åç«¯é¢è¯•ä¸€èˆ¬ä¼šè€ƒå“ªäº›é¢˜å‹ï¼Ÿ",
        "2025 å¹´æ•°æ®åˆ†æå¸ˆçš„ä¸»æµæŠ€èƒ½æ ˆæ˜¯ä»€ä¹ˆï¼Ÿ",
        "å¸®æˆ‘æœé›†ä¸€ä¸‹ AI Agent å²—ä½çš„å…¸å‹èŒè´£å’Œå¸¸è§æŠ€èƒ½è¦æ±‚ã€‚",
        "ç°åœ¨ Java é«˜çº§å·¥ç¨‹å¸ˆçš„è¡Œæƒ…æ€ä¹ˆæ ·ï¼Ÿå¤§æ¦‚å¤šå°‘è–ªèµ„ï¼Ÿ",
        "è¯·æŸ¥ä¸€ä¸‹ Spring Boot é¢è¯•é«˜é¢‘é¢˜æœ‰å“ªäº›ï¼Œå¹¶ç®€å•å½’ç±»ã€‚",
        "æœ€è¿‘ä¸¤å¹´å‰ç«¯å²—ä½æ›´çœ‹é‡å“ªäº›èƒ½åŠ›ï¼Ÿ",
        "å¸®æˆ‘äº†è§£ä¸€ä¸‹â€˜å¤§æ¨¡å‹ç®—æ³•å·¥ç¨‹å¸ˆâ€™å¸¸ç”¨çš„æŠ€æœ¯æ ˆå’Œæ–¹å‘ã€‚",
        "è¯·è°ƒç ”ä¸€ä¸‹å¤–ä¼å’Œäº’è”ç½‘å…¬å¸ç®€å†é£æ ¼å·®å¼‚æœ‰å“ªäº›ï¼Ÿ",
    ]

    # research_modifyï¼šè¦åˆ©ç”¨è°ƒç ”/JD/èŒƒä¾‹æ¥æ”¹ç®€å†ï¼ˆå¯¹æ ‡ã€æ ¹æ®è¦æ±‚ä¼˜åŒ–ã€å‚è€ƒç­‰ï¼‰
    # ToolRouter è¯­ä¹‰ï¼ˆè§ graph_workflow.pyï¼‰ï¼š
    # - web: å…¬å¸/JD/å¸‚åœº/å®æ—¶ä¿¡æ¯
    # - rag: ç®€å†å†™ä½œæŠ€å·§ã€STARèŒƒä¾‹ã€å†…éƒ¨çŸ¥è¯†
    # - both: äºŒè€…éƒ½éœ€è¦

    research_modify_web_prompts = [
        "æ ¹æ®å­—èŠ‚è·³åŠ¨åç«¯ JD çš„è¦æ±‚ï¼ˆå¯ä»¥å…ˆæŸ¥ä¸€ä¸‹æ ¸å¿ƒèƒ½åŠ›ç‚¹ï¼‰ï¼Œå¸®æˆ‘é‡å†™è¿™æ®µé¡¹ç›®ç»å†ï¼šè´Ÿè´£è®¢å•ç³»ç»Ÿå¼€å‘ã€‚",
        "è¯·å…ˆæœç´¢ä¸€ä¸‹ 2025 å¹´â€˜AI Agent å·¥ç¨‹å¸ˆâ€™å²—ä½ JD çš„å¸¸è§å…³é”®è¯ï¼Œå†æ®æ­¤ä¼˜åŒ–æˆ‘çš„æŠ€èƒ½æè¿°ï¼šç†Ÿæ‚‰ Pythonã€LangChainã€‚",
        "å¯¹æ ‡é˜¿é‡Œäº‘ DevOps å²—ä½è¦æ±‚ï¼ˆå…ˆæŸ¥ JDï¼‰ï¼Œä¼˜åŒ–æˆ‘çš„ç®€å†è¦ç‚¹ï¼šè´Ÿè´£å‘å¸ƒæµç¨‹ã€‚",
        "å…ˆæŸ¥ä¸€ä¸‹ç¾å›¢åç«¯å·¥ç¨‹å¸ˆå¸¸è§é¢è¯•/èƒ½åŠ›è¦æ±‚ï¼Œç„¶åæŠŠæˆ‘è¿™æ®µç»å†æ”¹å¾—æ›´è´´åˆï¼šåšè¿‡æ¥å£å¼€å‘ã€‚",
        "è¯·è°ƒç ”ä¸€ä¸‹å¤–ä¼ï¼ˆä¾‹å¦‚å¾®è½¯/è°·æ­Œï¼‰SWE ç®€å†å†™æ³•åå¥½ï¼Œå†æŒ‰é‚£ä¸ªé£æ ¼æ”¹å†™ï¼šåšè¿‡å¾®æœåŠ¡é¡¹ç›®ã€‚",
        "å…ˆæŸ¥ä¸€ä¸‹ 2025 å¹´ä¸Šæµ· Python åç«¯çš„ä¸»æµæŠ€æœ¯è¦æ±‚ï¼Œç„¶åæ®æ­¤ä¼˜åŒ–æˆ‘çš„æŠ€èƒ½æ ˆï¼šä¼š FastAPIã€Redisã€‚",
        "æ ¹æ®æœ€æ–°è¡Œä¸šå¯¹æ•°æ®åˆ†æå¸ˆçš„è¦æ±‚ï¼ˆè¯·å…ˆè°ƒç ”ï¼‰ï¼Œæ”¹å†™æˆ‘çš„æŠ€èƒ½æ¸…å•ï¼šSQLã€Excelã€Pythonã€‚",
        "å…ˆæŸ¥ä¸€ä¸‹å¤§æ¨¡å‹ç®—æ³•å·¥ç¨‹å¸ˆ JD å¸¸è§è¦æ±‚ï¼Œå†å¯¹æ ‡æ”¹å†™æˆ‘çš„é¡¹ç›®äº®ç‚¹ï¼šè®­ç»ƒè¿‡åˆ†ç±»æ¨¡å‹ã€‚",
        "è¯·å…ˆæœç´¢ä¸€ä¸‹å‰ç«¯é«˜çº§å·¥ç¨‹å¸ˆå²—ä½å¸¸è§è¦æ±‚ï¼Œå†æ®æ­¤æ”¹å†™æˆ‘çš„é¡¹ç›®ç»å†ï¼šåšè¿‡ä¸­åå°æ€§èƒ½ä¼˜åŒ–ã€‚",
        "å¯¹æ ‡æŸå¤´éƒ¨äº’è”ç½‘å…¬å¸åç«¯ JDï¼ˆå…ˆæŸ¥è¦æ±‚ï¼‰ï¼Œä¼˜åŒ–æˆ‘çš„è‡ªæˆ‘è¯„ä»·ï¼šç†Ÿæ‚‰åˆ†å¸ƒå¼ä¸é«˜å¹¶å‘ã€‚",
    ]

    research_modify_rag_prompts = [
        "å‚è€ƒ STAR æ³•åˆ™ï¼ŒæŠŠè¿™æ®µç»å†é‡å†™å¾—æ›´ä¸“ä¸šï¼šè´Ÿè´£è®¢å•ç³»ç»Ÿå¼€å‘ã€‚",
        "è¯·å‚è€ƒä¼˜ç§€ç®€å†å¸¸ç”¨è¡¨è¾¾ï¼Œæ¶¦è‰²è¿™æ®µç»å†å¹¶è¾“å‡ºæ›´å¼ºåŠ¨è¯ï¼šè´Ÿè´£æ¥å£å¼€å‘ä¸ç»´æŠ¤ã€‚",
        "ç”¨ STAR æ³•åˆ™æŠŠè¿™æ®µé¡¹ç›®ç»å†æ”¹å†™æˆ 3 æ¡è¦ç‚¹ï¼šåšè¿‡æ€§èƒ½ä¼˜åŒ–ã€‚",
        "å‚è€ƒç®€å†å†™ä½œæ¨¡æ¿ï¼ŒæŠŠè¿™æ®µæè¿°å†™å¾—æ›´é‡åŒ–ï¼šä¼˜åŒ–äº†ç³»ç»Ÿå“åº”é€Ÿåº¦ã€‚",
        "è¯·å‚è€ƒå¸¸è§çš„â€˜é¡¹ç›®èƒŒæ™¯-èŒè´£-ç»“æœâ€™å†™æ³•ï¼Œæ”¹å†™ï¼šå‚ä¸å¾®æœåŠ¡æ”¹é€ ã€‚",
        "å‚è€ƒé¢å‘æ‹›è˜å®˜çš„å†™æ³•ï¼ŒæŠŠè¿™æ®µç»å†æ”¹æˆæ›´æœ‰è¯´æœåŠ›ï¼šä¿®å¤çº¿ä¸Š bugï¼Œä¿éšœç¨³å®šæ€§ã€‚",
        "ç”¨ç®€å†èŒƒæ–‡çš„é£æ ¼ï¼ŒæŠŠè¿™æ®µç»å†æ”¹æˆæ›´ä¸“ä¸šï¼šè´Ÿè´£æœåŠ¡å™¨ç»´æŠ¤ã€‚",
        "å‚è€ƒå¸¸è§æŠ€æœ¯ç®€å†çš„æªè¾ï¼Œæ”¹å†™è¿™æ®µæŠ€èƒ½æè¿°ï¼šä¼š Pythonã€Redisã€MySQLã€‚",
        "è¯·å‚è€ƒ STAR èŒƒä¾‹ï¼ŒæŠŠè¿™æ®µç»å†è¡¥å…¨èƒŒæ™¯/è¡ŒåŠ¨/ç»“æœï¼šåšè¿‡æ—¥å¿—ç³»ç»Ÿã€‚",
        "å‚è€ƒä¼˜ç§€æ¡ˆä¾‹ï¼ŒæŠŠè¿™æ®µç»å†æ”¹æˆæ›´æ¸…æ™°çš„ 2-3 æ¡ bulletï¼šåšè¿‡ CI/CDã€‚",
    ]

    research_modify_both_prompts = [
        "å…ˆæŸ¥ä¸€ä¸‹ AI Agent å²—ä½ JD çš„æ ¸å¿ƒæŠ€èƒ½ç‚¹ï¼Œå†ç»“åˆ STAR æ³•åˆ™é‡å†™è¿™æ®µç»å†ï¼šåšè¿‡èŠå¤©æœºå™¨äººã€‚",
        "è¯·å…ˆè°ƒç ” 2025 å¹´èµ„æ·±å‰ç«¯å¸¸è§è¦æ±‚ï¼Œå†å‚è€ƒå¤§å‚ç®€å†å†™æ³•æ”¹å†™æˆ‘çš„é¡¹ç›®äº®ç‚¹ï¼šåšè¿‡ä¸­åå°ã€‚",
        "å…ˆæœé›† Python åç«¯é«˜å¹¶å‘å¸¸è§å…³é”®è¯ï¼Œå†å‚è€ƒä¼˜ç§€èŒƒä¾‹æŠŠè¿™æ®µç»å†å†™å¾—æ›´é‡åŒ–ï¼šä¼˜åŒ–äº†æ¥å£æ€§èƒ½ã€‚",
        "è¯·å…ˆæŸ¥ä¸€ä¸‹æ•°æ®åˆ†æå¸ˆå²—ä½ä¸»æµæŠ€èƒ½æ ˆï¼Œå†æŒ‰ç®€å†èŒƒæ–‡çš„é£æ ¼æ”¹å†™æˆ‘çš„æŠ€èƒ½æè¿°ï¼šä¼š SQLã€Excelã€‚",
        "å…ˆæœç´¢å¤–ä¼ç®€å†é£æ ¼å·®å¼‚ï¼Œå†å‚è€ƒ STAR æ¨¡æ¿é‡å†™ï¼šä¸»å¯¼å¾®æœåŠ¡æ”¹é€ ã€‚",
        "å…ˆæŸ¥ä¸€ä¸‹ DevOps å…³é”®è¯ï¼ˆIaCã€å¯è§‚æµ‹æ€§ã€CI/CDï¼‰ï¼Œå†å‚è€ƒä¼˜ç§€ç®€å†æªè¾æ”¹å†™ï¼šç»´æŠ¤å‘å¸ƒæµç¨‹ã€‚",
        "è¯·å…ˆè°ƒç ”å¤§æ¨¡å‹ç®—æ³•å·¥ç¨‹å¸ˆå¸¸ç”¨æŠ€æœ¯æ ˆï¼Œå†å‚è€ƒå¤§å‚ç®€å†å†™æ³•ä¼˜åŒ–ï¼šç†Ÿæ‚‰ PyTorchã€‚",
        "å…ˆæŸ¥ä¸€ä¸‹æŸå¤§å‚åç«¯ JD çš„è¦æ±‚ï¼Œå†ç”¨ STAR æ³•åˆ™é‡å†™ï¼šè´Ÿè´£è®¢å•ç³»ç»Ÿå¼€å‘ã€‚",
        "è¯·å…ˆæœç´¢é«˜çº§ Python åç«¯è¦æ±‚ï¼Œå†å‚è€ƒç®€å†èŒƒæ–‡é‡å†™ï¼šåšè¿‡æ”¯ä»˜ç³»ç»Ÿå¼€å‘ä¸ç»´æŠ¤ã€‚",
        "å…ˆè°ƒç ”å‰ç«¯å²—ä½è¶‹åŠ¿ï¼Œå†å‚è€ƒä¼˜ç§€èŒƒä¾‹æŠŠæˆ‘çš„é¡¹ç›®ç»å†å†™å¾—æ›´ä¸“ä¸šï¼šåšè¿‡æ€§èƒ½ä¼˜åŒ–ã€‚",
    ]

    buckets: Dict[str, List[str]] = {
        "chat": chat_prompts,
        "modify": modify_prompts,
        "research_consult": research_consult_prompts,
    }

    for intent in INTENTS:
        if intent == "research_modify":
            continue
        if intent not in buckets:
            raise ValueError(f"Missing intent bucket: {intent}")
        if len(buckets[intent]) != 10:
            raise ValueError(f"Intent '{intent}' needs 10 examples, got {len(buckets[intent])}")

    if len(research_modify_web_prompts) != 10:
        raise ValueError(f"research_modify:web needs 10 examples, got {len(research_modify_web_prompts)}")
    if len(research_modify_rag_prompts) != 10:
        raise ValueError(f"research_modify:rag needs 10 examples, got {len(research_modify_rag_prompts)}")
    if len(research_modify_both_prompts) != 10:
        raise ValueError(f"research_modify:both needs 10 examples, got {len(research_modify_both_prompts)}")

    cases: List[Case] = []
    for intent in INTENTS:
        if intent == "research_modify":
            continue
        for prompt in buckets[intent]:
            cases.append(Case(expected=intent, prompt=prompt))

    for prompt in research_modify_web_prompts:
        cases.append(Case(expected="research_modify", expected_tool="web", prompt=prompt))
    for prompt in research_modify_rag_prompts:
        cases.append(Case(expected="research_modify", expected_tool="rag", prompt=prompt))
    for prompt in research_modify_both_prompts:
        cases.append(Case(expected="research_modify", expected_tool="both", prompt=prompt))

    return cases


async def classify(prompt: str) -> str:
    decision = await llm_service.process_supervisor_request(prompt, history=[])
    # Supervisor è¾“å‡ºå­—æ®µæ˜¯ next_agent
    predicted = (decision.get("next_agent") or "").strip()
    return predicted


async def choose_tool(query: str) -> str:
    """å¤ç”¨ graph_workflow.py ä¸­çš„ ToolRouter promptï¼Œè¾“å‡º web/rag/bothã€‚"""

    router_prompt = (
        f"Analyze the following query and decide which tool to use.\n"
        f"Query: {query}\n\n"
        f"Tools:\n"
        f"1. 'web': For specific company info, JD (Job Description), market data, real-time info.\n"
        f"2. 'rag': For resume writing tips, STAR method examples, standard phrases, internal knowledge.\n"
        f"3. 'both': If both are needed.\n\n"
        f"Return only one word: 'web', 'rag', or 'both'."
    )

    try:
        router_response = await llm_service.llm.ainvoke([HumanMessage(content=router_prompt)])
        tool_choice = (router_response.content or "").strip().lower()
    except Exception:
        tool_choice = "both"

    if tool_choice not in RESEARCH_MODIFY_TOOLS:
        tool_choice = "both"
    return tool_choice


def _pct(n: int, d: int) -> str:
    if d == 0:
        return "0.00%"
    return f"{(n / d) * 100:.2f}%"


async def main():
    cases = build_cases()

    total = 0
    correct_combined = 0

    # å¤§ç±»å‡†ç¡®ç‡ï¼ˆåªçœ‹ next_agentï¼‰
    correct_top = 0

    per_label_total: Dict[str, int] = defaultdict(int)
    per_label_correct: Dict[str, int] = defaultdict(int)

    per_top_total: Dict[str, int] = defaultdict(int)
    per_top_correct: Dict[str, int] = defaultdict(int)

    sub_total = 0
    sub_correct = 0
    per_tool_total: Dict[str, int] = defaultdict(int)
    per_tool_correct: Dict[str, int] = defaultdict(int)

    confusion: Dict[str, Dict[str, int]] = defaultdict(lambda: defaultdict(int))

    print("========================================")
    print("ğŸ§ª æ„å›¾åˆ†ç±»å‡†ç¡®ç‡è¯„æµ‹")
    print("- å¤§ç±»ï¼šSupervisor è¾“å‡º next_agentï¼ˆchat/modify/research_consult/research_modifyï¼‰")
    print("- å­ç±»ï¼šå½“ next_agent=research_modify æ—¶ï¼ŒToolRouter ç»†åˆ† web/rag/both")
    print("========================================")

    for idx, case in enumerate(cases, start=1):
        decision = await llm_service.process_supervisor_request(case.prompt, history=[])
        predicted_top = (decision.get("next_agent") or "").strip()
        predicted_tool: Optional[str] = None

        if predicted_top == "research_modify":
            query = (decision.get("search_query") or "").strip() or case.prompt
            predicted_tool = await choose_tool(query)

        expected_top = case.expected
        expected_tool = case.expected_tool

        expected_label = expected_top
        predicted_label = predicted_top
        if expected_top == "research_modify":
            expected_label = f"research_modify:{expected_tool}"
        if predicted_top == "research_modify":
            predicted_label = f"research_modify:{predicted_tool}"

        total += 1
        per_label_total[expected_label] += 1
        confusion[expected_label][predicted_label] += 1

        per_top_total[expected_top] += 1

        ok_top = predicted_top == expected_top
        if ok_top:
            correct_top += 1
            per_top_correct[expected_top] += 1

        ok_combined = predicted_label == expected_label
        if ok_combined:
            correct_combined += 1
            per_label_correct[expected_label] += 1

        if expected_top == "research_modify":
            sub_total += 1
            if predicted_top == "research_modify":
                per_tool_total[expected_tool or ""] += 1
                if predicted_tool == expected_tool:
                    sub_correct += 1
                    per_tool_correct[expected_tool or ""] += 1

        status = "âœ…" if ok_combined else "âŒ"
        exp_show = expected_label
        pred_show = predicted_label
        print(f"[{idx:02d}/{len(cases)}] {status} æœŸæœ›={exp_show:<22} é¢„æµ‹={pred_show:<22} | {case.prompt}")

    print("\n----------------------------------------")
    print(f"æ€»ä½“æ­£ç¡®ç‡(å¤§ç±»): {correct_top}/{total} = {_pct(correct_top, total)}")
    print(f"æ€»ä½“æ­£ç¡®ç‡(å¤§ç±»+å­ç±»): {correct_combined}/{total} = {_pct(correct_combined, total)}")

    print("\nåˆ†å¤§ç±»æ­£ç¡®ç‡:")
    for intent in INTENTS:
        c = per_top_correct[intent]
        t = per_top_total[intent]
        print(f"- {intent:<15}: {c:02d}/{t:02d} = {_pct(c, t)}")

    print("\nresearch_modify å­ç±»æ­£ç¡®ç‡ (ä»…åœ¨æœŸæœ›ä¸º research_modify çš„æ ·ä¾‹ä¸Šç»Ÿè®¡):")
    print(f"- å­ç±»æ€»ä½“: {sub_correct}/{sub_total} = {_pct(sub_correct, sub_total)}")
    for tool in RESEARCH_MODIFY_TOOLS:
        c = per_tool_correct[tool]
        t = per_tool_total[tool]
        print(f"- {tool:<5}: {c:02d}/{t:02d} = {_pct(c, t)}")

    print("\nåˆ†æ ‡ç­¾(å«å­ç±»)æ­£ç¡®ç‡:")
    ordered_labels = [
        "chat",
        "modify",
        "research_consult",
        "research_modify:web",
        "research_modify:rag",
        "research_modify:both",
    ]
    for label in ordered_labels:
        c = per_label_correct[label]
        t = per_label_total[label]
        print(f"- {label:<22}: {c:02d}/{t:02d} = {_pct(c, t)}")

    print("\næ··æ·†ç»Ÿè®¡ (æœŸæœ› -> é¢„æµ‹: æ¬¡æ•°):")
    for expected_label in ordered_labels:
        row = confusion[expected_label]
        parts = []
        for predicted_label in ordered_labels:
            cnt = row.get(predicted_label, 0)
            if cnt:
                parts.append(f"{predicted_label}={cnt}")
        parts_str = ", ".join(parts) if parts else "(æ— )"
        print(f"- {expected_label:<22} -> {parts_str}")


if __name__ == "__main__":
    asyncio.run(main())
